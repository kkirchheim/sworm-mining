{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# LDA HPO\n",
    "\n",
    "Hyper parameter optimization for the LDA topic models.\n",
    "\n",
    "Calculating coherence and model perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from os.path import join\n",
    "import src.constants as const\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "sb.set()\n",
    "df = pd.read_pickle(const.JOURNALS_DF)\n",
    "\n",
    "df_other = df[~df[\"dc:description:tokenized\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_docs = len(df_other)\n",
    "texts = df_other[\"dc:description:tokenized\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "documents = texts.str.split().values\n",
    "\n",
    "print(\"Creating dict\")\n",
    "dictionary = corpora.Dictionary(documents)\n",
    "\n",
    "print(\"Creating corpus\")\n",
    "corpus = [dictionary.doc2bow(doc, allow_update=True) for doc in documents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scores = {}\n",
    "\n",
    "for n_topics in range(5,100, 5):\n",
    "    lda_model = LdaMulticore(corpus=corpus,\n",
    "                         id2word=dictionary,\n",
    "                         random_state=100,\n",
    "                         num_topics=n_topics,\n",
    "                         passes=10,\n",
    "                         chunksize=1000,\n",
    "                         batch=False,\n",
    "                         alpha='asymmetric',\n",
    "                         decay=0.5,\n",
    "                         offset=64,\n",
    "                         eta=None,\n",
    "                         eval_every=0,\n",
    "                         iterations=100,\n",
    "                         gamma_threshold=0.001,\n",
    "                         per_word_topics=True)\n",
    "\n",
    "    perplexity = lda_model.log_perplexity(corpus)\n",
    "    cm = CoherenceModel(model=lda_model, corpus=corpus, texts=documents, coherence=\"u_mass\", dictionary=dictionary)\n",
    "    coherence = cm.get_coherence()\n",
    "    scores[n_topics] = (coherence, perplexity)\n",
    "    print(f\"{n_topics} -> Coherence: {coherence} Perplexity: {perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# lda_model.save(join(const.MODELS_DIR, \"lda-gensim\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lda_model.print_topics(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for c in lda_model[corpus[:10]]:\n",
    "    print(\"Document Topics      : \", c[0])      # [(Topics, Perc Contrib)]\n",
    "    print(\"Word id, Topics      : \", c[1][:3])  # [(Word id, [Topics])]\n",
    "    print(\"Phi Values (word id) : \", c[2][:2])  # [(Word id, [(Topic, Phi Value)])]\n",
    "    print(\"Word, Topics         : \", [(dictionary[wd], topic) for wd, topic in c[1][:2]])   # [(Word, [Topics])]\n",
    "    print(\"Phi Values (word)    : \", [(dictionary[wd], topic) for wd, topic in c[2][:2]])  # [(Word, [(Topic, Phi Value)])]\n",
    "    print(\"------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "texts = df[\"dc:description:tokenized\"]\n",
    "documents = texts.str.split().values\n",
    "corpus = [dictionary.doc2bow(doc, allow_update=True) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = lda_model[corpus]\n",
    "predictions = list(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "topics = []\n",
    "props = []\n",
    "\n",
    "for result in predictions:\n",
    "    topics.append([topic[0] for topic in result[0]])\n",
    "    props.append([topic[1] for topic in result[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"lda:topics\"] = pd.Series(topics, index=df.index)\n",
    "df[\"lda:topics:top\"] = pd.Series([topic[0] for topic in topics if len(topic) > 0], index=df.index)\n",
    "df[\"lda:topics:props\"] = pd.Series(props, index=df.index)\n",
    "df[\"lda:topics:props:top\"] = pd.Series([p[0] for p in props if len(p) > 0], index=df.index)\n",
    "\n",
    "df.to_pickle(join(const.ARTIFACTS_DIR, \"journals-with-topics.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data= []\n",
    "\n",
    "for n in range(20):\n",
    "    terms = lda_model.get_topic_terms(n, topn=20)\n",
    "    terms = [dictionary.id2token[t[0]] for t in terms]\n",
    "    data.append({\"terms\": terms})\n",
    "\n",
    "topid_df = pd.DataFrame(data)\n",
    "topid_df.to_pickle(join(const.ARTIFACTS_DIR, \"topics.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Mallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from gensim.models.wrappers import LdaMallet\n",
    "# mallet_path = \"/home/ki/crypt/git/Mallet/bin/mallet\"\n",
    "#\n",
    "# lda_mallet = LdaMallet(mallet_path,\n",
    "#                        corpus=corpus,\n",
    "#                        num_topics=10,\n",
    "#                        alpha=50,\n",
    "#                        id2word=dictionary,\n",
    "#                        workers=10,\n",
    "#                        prefix=None,\n",
    "#                        optimize_interval=0,\n",
    "#                        iterations=1000,\n",
    "#                        topic_threshold=0.0,\n",
    "#                        random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# lda_mallet.print_topics(-1)\n",
    "#\n",
    "# lda_model2 =  gensim.models.wrappers.ldamallet.malletmodel2ldamodel(lda_mallet)\n",
    "# lda_model.save(join(const.MODELS_DIR, \"lda-gensim-mallet\"))\n",
    "# for c in lda_model2[corpus[:10]]:\n",
    "#     print(c)\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scopus37",
   "language": "python",
   "name": "scopus37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
